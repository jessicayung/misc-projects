{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPL vs ESL Speaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Import and Preprocess Data\n",
    "\n",
    "### 1.1 Import data and delete unwanted datapoints\n",
    "1. Copy speaker tabs from WUDC2017, EUDC2016, Oxford IV 2016, Cambridge IV 2016.\n",
    "\n",
    "2. Remove speakers who have not completed all five rounds or are swing speakers from the tab.\n",
    "    * If speakers have not completed all five rounds, they may have been ill and so other confounding factors likely affected their performance.\n",
    "    * Swing speakers may not be  taking the tournament seriously. Their on-tab names may also be wrong.\n",
    "        * Took out Swing A in EUDC2016 for completeness even though \n",
    "    * The average speaks also tend to wrong in that they are an average across rounds-including-those-where-said-speaker-got-zero-speaks.\n",
    "\n",
    "### 1.2 Convert data into desired format\n",
    "1. Create dummy variable columns for EPL, ESL, EFL and ESL_or_EFL.\n",
    "    * EFL applies only to WUDC and EUDC.\n",
    "    * Distinguishing between ESL and EFL speakers may be of interest, so we will keep both categories and add an `ESL_or_EFL` dummy variable.\n",
    "    * Method: use formula `=IF(C2,1,0)`, for each cell in the `is_esl` column where column C is the speaker's ESL rank and 2 is the speaker's row number.\n",
    "2. Create datasets:\n",
    "    * (i) Use average speaks in a tournament per speaker only.\n",
    "    * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in tab data (with `is_esl` column)\n",
    "eudc2016 = pd.read_csv(\"data/eudc2016.csv\")\n",
    "wudc2017 = pd.read_csv(\"data/wudc2017.csv\")\n",
    "oxiv2016 = pd.read_csv(\"data/oxiv2016.csv\")\n",
    "camiv2016 = pd.read_csv(\"data/camiv2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_esl</th>\n",
       "      <th>ENL</th>\n",
       "      <th>ESL</th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Team</th>\n",
       "      <th>Team Points</th>\n",
       "      <th>Speaker Points</th>\n",
       "      <th>AVG</th>\n",
       "      <th>#1</th>\n",
       "      <th>#2</th>\n",
       "      <th>#3</th>\n",
       "      <th>#4</th>\n",
       "      <th>#5</th>\n",
       "      <th>#6</th>\n",
       "      <th>#7</th>\n",
       "      <th>#8</th>\n",
       "      <th>#9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael Dunn Goekjian</td>\n",
       "      <td>PEP A</td>\n",
       "      <td>22</td>\n",
       "      <td>762</td>\n",
       "      <td>84.7</td>\n",
       "      <td>87</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dan Lahav</td>\n",
       "      <td>Tel Aviv A</td>\n",
       "      <td>19</td>\n",
       "      <td>759</td>\n",
       "      <td>84.3</td>\n",
       "      <td>86</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kit Mercer</td>\n",
       "      <td>Durham A</td>\n",
       "      <td>23</td>\n",
       "      <td>753</td>\n",
       "      <td>83.7</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joshua Bailey</td>\n",
       "      <td>Durham A</td>\n",
       "      <td>23</td>\n",
       "      <td>753</td>\n",
       "      <td>83.7</td>\n",
       "      <td>84</td>\n",
       "      <td>85</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Daniel Bramble</td>\n",
       "      <td>LSE A</td>\n",
       "      <td>21</td>\n",
       "      <td>749</td>\n",
       "      <td>83.2</td>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_esl  ENL  ESL                Speaker        Team  Team Points  \\\n",
       "0       0    1  NaN  Michael Dunn Goekjian       PEP A           22   \n",
       "1       1    2  1.0              Dan Lahav  Tel Aviv A           19   \n",
       "2       0    3  NaN             Kit Mercer    Durham A           23   \n",
       "3       0    3  NaN          Joshua Bailey    Durham A           23   \n",
       "4       0    5  NaN         Daniel Bramble       LSE A           21   \n",
       "\n",
       "   Speaker Points   AVG  #1  #2  #3  #4  #5  #6  #7  #8  #9  \n",
       "0             762  84.7  87  83  84  85  86  87  84  84  82  \n",
       "1             759  84.3  86  84  82  86  85  81  83  91  81  \n",
       "2             753  83.7  83  85  82  85  80  82  83  85  88  \n",
       "3             753  83.7  84  85  82  83  82  83  83  85  86  \n",
       "4             749  83.2  79  85  83  81  82  85  86  83  85  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview one tab\n",
    "eudc2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List the tabs we have for use in following code\n",
    "list_of_tabs = [(wudc2017, \"wudc2017\"), (oxiv2016, \"oxiv2016\"), \n",
    "                (camiv2016, \"camiv2016\"),(eudc2016, \"eudc2016\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to store information\n",
    "# defaultdict prevents KeyErrors\n",
    "average_speaks_per_tournament = defaultdict(dict)\n",
    "\n",
    "# Add average speaks and ESL status per speaker to our dictionary\n",
    "for tournament in list_of_tabs:\n",
    "    # Unpack tuple values\n",
    "    tournament_name = tournament[1]\n",
    "    tournament_tab = tournament[0]\n",
    "    for row_index in range(len(tournament_tab)):\n",
    "        row = tournament_tab.loc[row_index]\n",
    "        speaker_name = row['Speaker']\n",
    "        speaker_average = row['AVG']\n",
    "        # Add tournament speaks average to speaker record\n",
    "        speaker_record = average_speaks_per_tournament[speaker_name]\n",
    "        speaker_record[tournament_name + \"_avg\"] = speaker_average\n",
    "        # Add is_esl to speaker record\n",
    "        speaker_record['is_esl_' + tournament_name] = row['is_esl']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# View dictionary \n",
    "# to check it's approx what we expect\n",
    "average_speaks_per_tournament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-9ed0260332b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mspeaker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maverage_speaks_per_tournament\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Should not hard code this but I'm lazy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mspeaker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_esl'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_esl_eudc2016'\u001b[0m\u001b[0;34m]\u001b[0m                         \u001b[0;32mor\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_esl_wudc2017'\u001b[0m\u001b[0;34m]\u001b[0m                         \u001b[0;32mor\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_esl_oxiv2016'\u001b[0m\u001b[0;34m]\u001b[0m                         \u001b[0;32mor\u001b[0m \u001b[0mspeaker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_esl_camiv2016'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "# Combine all esl indicators using OR\n",
    "\n",
    "# this doesn't work! :(\n",
    "# TODO: Fix this. For now am doing this in Google Sheets instead.\n",
    "for speaker in average_speaks_per_tournament:\n",
    "    # Should not hard code this but I'm lazy\n",
    "    speaker['is_esl'] = speaker['is_esl_eudc2016'] \\\n",
    "                        or speaker['is_esl_wudc2017'] \\\n",
    "                        or speaker['is_esl_oxiv2016'] \\\n",
    "                        or speaker['is_esl_camiv2016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert dictionary to a dataframe to export\n",
    "average_speaks_per_tournament_df = \\\n",
    "    pd.DataFrame.from_dict(average_speaks_per_tournament, orient=\"index\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# View dataframe to check it's what we expect\n",
    "average_speaks_per_tournament_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attempt to combine ESL indicators again\n",
    "# and fail again :(\n",
    "for row_index in range(len(average_speaks_per_tournament_df)):\n",
    "    row = average_speaks_per_tournament_df.iloc[row_index]\n",
    "    row['is_esl'] = row['is_esl_wudc2017'] or row['is_esl_oxiv2016'] \\\n",
    "                    or row['is_esl_camiv2016'] or row['is_esl_eudc2016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_esl_wudc2017</th>\n",
       "      <th>wudc2017_avg</th>\n",
       "      <th>eudc2016_avg</th>\n",
       "      <th>is_esl_eudc2016</th>\n",
       "      <th>oxiv2016_avg</th>\n",
       "      <th>is_esl_oxiv2016</th>\n",
       "      <th>is_esl_camiv2016</th>\n",
       "      <th>camiv2016_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ABEL LAW</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Luke</th>\n",
       "      <td>0.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aaron Schaffer-Neitz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>77.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abhi Kulgod</th>\n",
       "      <td>0.0</td>\n",
       "      <td>76.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abhik Pant</th>\n",
       "      <td>1.0</td>\n",
       "      <td>70.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      is_esl_wudc2017  wudc2017_avg  eudc2016_avg  \\\n",
       "ABEL LAW                          NaN           NaN           NaN   \n",
       "Aaron Luke                        0.0          80.6           NaN   \n",
       "Aaron Schaffer-Neitz              0.0          77.2           NaN   \n",
       "Abhi Kulgod                       0.0          76.2           NaN   \n",
       "Abhik Pant                        1.0          70.1           NaN   \n",
       "\n",
       "                      is_esl_eudc2016  oxiv2016_avg  is_esl_oxiv2016  \\\n",
       "ABEL LAW                          NaN          77.2              1.0   \n",
       "Aaron Luke                        NaN          77.0              0.0   \n",
       "Aaron Schaffer-Neitz              NaN          75.4              0.0   \n",
       "Abhi Kulgod                       NaN           NaN              NaN   \n",
       "Abhik Pant                        NaN           NaN              NaN   \n",
       "\n",
       "                      is_esl_camiv2016  camiv2016_avg  \n",
       "ABEL LAW                           NaN            NaN  \n",
       "Aaron Luke                         0.0           78.2  \n",
       "Aaron Schaffer-Neitz               0.0           76.6  \n",
       "Abhi Kulgod                        NaN            NaN  \n",
       "Abhik Pant                         NaN            NaN  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View df again: combining ESL indicators is still not working!\n",
    "average_speaks_per_tournament_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the dataframe to a CSV \n",
    "# because I'm lazy and want to manipulate data in Google Sheets \n",
    "# and then run regs in Stata\n",
    "average_speaks_per_tournament_df.to_csv(path_or_buf=\"avg_speaks_per_tournament_no_combined_esl_status.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deprecated code:\n",
    "```\n",
    "if speaker_record['is_esl'] is None or speaker_record['is_esl'] == 0:\n",
    "            speaker_record['is_esl'] = row['is_esl']\n",
    "```\n",
    "Returns \n",
    "```\n",
    "KeyError                                  Traceback (most recent call last)\n",
    "<ipython-input-25-15a25a89b6b3> in <module>()\n",
    "     10         speaker_record = average_speaks_per_tournament[speaker_name]\n",
    "     11         speaker_record[tournament_name + \"_avg\"] = speaker_average\n",
    "---> 12         if speaker_record['is_esl'] is None or speaker_record['is_esl'] == 0:\n",
    "     13             speaker_record['is_esl'] = row['is_esl']\n",
    "\n",
    "KeyError: 'is_esl'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestions\n",
    "### Things to do suggestions\n",
    "* Add dummy variables `top_quartile`, `bottom_quartile` or similar to see if ESL bias 'increases down the tab'.\n",
    "    * May have issues with interpreting the coefficients\n",
    "* Factoring in name or institutional recognition (though this probably doesn't affected ESL speakers exclusively or more than EPL speakers so it seems more appropriate for a separate study. And presumably effects apply across all tournaments so *shrugs*.)\n",
    "* Region chairs are from\n",
    "* Region speakers are from\n",
    "* Identify where the drop in average speaks comes from (drop in speaker's highest speaks or lowest or across the board)\n",
    "    * Hypothesis that bad speeches are judged more harshly at Oxbridge IVs (Roel Becker)\n",
    "* Over-representation of high scoring speakers at Oxbridge (meh)\n",
    "    * this will only matter in so far as it pulls up speaks in general since we're comparing an individual's speaks at WUDC vs Oxbridge IVs.\n",
    "* Having judges who regularly judge certain ESL speakers and give them high speaks may make it easier for those judges to give 86s and 85s rather than 82s. (Berman)\n",
    "    * Okay I don't see an easy way of correcting for this, also likely applies to both ESL and EPL?\n",
    "    \n",
    "### Method based suggestions\n",
    "* Something two way ANOVA optionally with repeated measures\n",
    "* Separate judges willing to make use of the 85-90 range (Joe Roussos).\n",
    "    * If you look just at a small sample of teams (those that the top 15 speakers were in, say) then you're vulnerable to the confounding effect of encountering high-scoring judges more frequently at Cambridge, vs. at Worlds. \n",
    "    * and Effect of CA teams having different allocation strategies\n",
    "        * In general WUDC seems to have allocated higher ranked judges closer to the middle of the tab than Cambridge's more manual system \n",
    "            * and proportion of ESL teams in top rooms may have been different (Berman)\n",
    "                * This is valid only if for each ESL speaker, they are more likely to have been in a room with a high-speak-giving judge in Cam/Ox IV than not, and this effect is significantly different than for EPL speakers (whose speaks we used).\n",
    "    * How to test for this / correct for it:\n",
    "        1. Use Tabbie data across tournaments to track the kinds of scores judges give. Compare how judge A ranks a speaker, compared to the average speaks they get. In this way you can test my hypothesis and, if correct, identify the high scorers for step 2. \n",
    "\n",
    "        2. Correct for relative differences in contact with high scorers in your regression. Ideal comparison points are those with similar contact across all competitions tested.\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
